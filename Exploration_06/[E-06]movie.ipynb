{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912aa5ba",
   "metadata": {},
   "source": [
    "# 6-11. 프로젝트 : 네이버 영화리뷰 감성분석 도전하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1345f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f80c8",
   "metadata": {},
   "source": [
    "# 2) 데이터로더 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7315f3",
   "metadata": {},
   "source": [
    "## 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b42ac088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)  # 단어사전에 등재할 단어 개수 지정\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268078f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6253d4cb",
   "metadata": {},
   "source": [
    "## 1-2. 단어사전 확인 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "588488fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 단어사전 확인\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])      # 'the' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87201915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "# index를 3씩 뒤로 밀기\n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 4개 인덱스는 사전에 정의된 것으로 추가\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "# 변경된 인덱스 확인\n",
    "print(index_to_word[1])      # '<BOS>' 가 출력됩니다.\n",
    "print(word_to_index['the'])  # 4 가 출력됩니다.\n",
    "print(index_to_word[4])      # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea036040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# decode한 문장과 라벨을 비교하여 일치하는지 확인\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13b45b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fe13c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "    \n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "    \n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "        \n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "        \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "171e9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fc96e2",
   "metadata": {},
   "source": [
    "## 1-3. 모델 구성을 위한 데이터 분석 및 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "497f4380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "# 텍스트데이터 문장길이의 리스트 생성\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균, 최대값, 표준편차 계산\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예시) 최대 길이를 (평균 + 2*표준편차)로 계산\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80ef8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146182, 41)\n"
     ]
    }
   ],
   "source": [
    "# padding으로 문장 길이 맞추기\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                       value=word_to_index[\"<PAD>\"],\n",
    "                                       padding='post', # 혹은 'pre'\n",
    "                                       maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                       value=word_to_index[\"<PAD>\"],\n",
    "                                       padding='post', # 혹은 'pre'\n",
    "                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7487213",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train[:100000]\n",
    "y = y_train[:100000]\n",
    "x_val = x_train[100000:]\n",
    "y_val = y_train[100000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a3f7b9",
   "metadata": {},
   "source": [
    "# 2. 딥러닝 모델 설계와 훈련\n",
    "\n",
    "## 2-1. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adecba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f859cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 데이터셋 25000건 중 10000건을 분리하여 validation set으로 사용\n",
    "x_val = x_train[:10000]  \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건은 train set\n",
    "partial_x_train = x_train[10000:] \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613ff60",
   "metadata": {},
   "source": [
    "# 2-2. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e08edae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 - 3s - loss: 0.5784 - accuracy: 0.7597 - val_loss: 0.5609 - val_accuracy: 0.7440\n",
      "Epoch 2/10\n",
      "30/30 - 1s - loss: 0.5825 - accuracy: 0.7120 - val_loss: 0.5666 - val_accuracy: 0.7217\n",
      "Epoch 3/10\n",
      "30/30 - 1s - loss: 0.5306 - accuracy: 0.7664 - val_loss: 0.5813 - val_accuracy: 0.7513\n",
      "Epoch 4/10\n",
      "30/30 - 1s - loss: 0.5326 - accuracy: 0.7781 - val_loss: 0.5476 - val_accuracy: 0.7628\n",
      "Epoch 5/10\n",
      "30/30 - 1s - loss: 0.6855 - accuracy: 0.6682 - val_loss: 0.9533 - val_accuracy: 0.5190\n",
      "Epoch 6/10\n",
      "30/30 - 1s - loss: 0.7193 - accuracy: 0.6336 - val_loss: 0.5988 - val_accuracy: 0.7560\n",
      "Epoch 7/10\n",
      "30/30 - 1s - loss: 0.5401 - accuracy: 0.7791 - val_loss: 0.5598 - val_accuracy: 0.7477\n",
      "Epoch 8/10\n",
      "30/30 - 1s - loss: 0.5228 - accuracy: 0.7803 - val_loss: 0.5503 - val_accuracy: 0.7615\n",
      "Epoch 9/10\n",
      "30/30 - 1s - loss: 0.5148 - accuracy: 0.7900 - val_loss: 0.5513 - val_accuracy: 0.7593\n",
      "Epoch 10/10\n",
      "30/30 - 1s - loss: 0.5131 - accuracy: 0.7881 - val_loss: 0.5540 - val_accuracy: 0.7553\n"
     ]
    }
   ],
   "source": [
    "# model 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "            \n",
    "epochs=10  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다.\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=epochs,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val),\n",
    "                   verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47667d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.5619 - accuracy: 0.7488\n",
      "[0.5618936419487, 0.7488399744033813]\n"
     ]
    }
   ],
   "source": [
    "# test set으로 model 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a91ec",
   "metadata": {},
   "source": [
    "## 2-3. Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae9e1ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# history 변수에 저장된 항목 확인\n",
    "history_dict = history.history\n",
    "print(history_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8af4563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')  # \"bo\"는 \"파란색 점\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')  # \"b\"는 \"파란 실선\"\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79fedf6",
   "metadata": {},
   "source": [
    "## 3. Word2Vec의 적용\n",
    "\n",
    "### 3-1. 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6709fb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 레이어 차원 확인\n",
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f96c326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장\n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(특수문자 4개는 제외)만큼의 워드 벡터를 파일에 기록\n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da1d3b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04504767, -0.07745239, -0.00593156, -0.07198162, -0.01784263,\n",
       "       -0.00328681, -0.06070649,  0.05011696, -0.02296268,  0.0649903 ,\n",
       "       -0.07696186,  0.05450249,  0.01509404, -0.00955022,  0.0686805 ,\n",
       "       -0.06397891], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "# 파일에 기록된 임베딩 파라미터를 읽어서 word vector로 활용\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05f15dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seven', 0.9350764155387878),\n",
       " ('makes', 0.9257311224937439),\n",
       " ('glad', 0.9237133264541626),\n",
       " ('top', 0.9197701215744019),\n",
       " ('abandoned', 0.9146977066993713),\n",
       " ('mouthed', 0.9138608574867249),\n",
       " ('favorites', 0.9137330651283264),\n",
       " ('fully', 0.9132468104362488),\n",
       " ('doris', 0.9111425876617432),\n",
       " ('resist', 0.9103097319602966)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사한 단어와 그 유사도 확인\n",
    "word_vectors.similar_by_word(\"like\")  # 학습이 잘 되지 않아 별로 유사하지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5c7d4",
   "metadata": {},
   "source": [
    "### 3-2. Word2Vec 임베딩 활용하여 성능 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ef6cb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624/127125989.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vector = word2vec['굳']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.007806  ,  0.02528994,  1.298106  , -0.60845226, -0.54713094,\n",
       "       -0.21371064,  0.13086885,  1.0785574 , -0.10013311,  0.33208925,\n",
       "       -0.9791137 , -0.18183775, -1.4690981 ,  0.3885967 ,  0.4037741 ,\n",
       "        0.41902122,  0.43593058, -0.69959414,  0.85953486, -1.720156  ,\n",
       "       -0.13397624,  0.12760656,  0.00936507,  1.517197  ,  0.44761622,\n",
       "        0.21009429,  0.59510446, -1.155584  , -0.02006225, -0.7506223 ,\n",
       "        0.65521383,  0.96242464, -0.54606813, -0.2683764 ,  0.861321  ,\n",
       "       -0.4421176 ,  0.71351266,  0.68796396, -0.34496003, -0.1751155 ,\n",
       "        0.9672179 ,  1.3559934 ,  0.47632736, -0.46820235,  0.8295786 ,\n",
       "       -0.49501127,  1.621534  ,  0.4855655 ,  0.169487  , -0.2699588 ,\n",
       "       -0.8880298 , -1.1619668 , -0.2655645 ,  0.8749546 , -0.89623314,\n",
       "       -0.249976  , -1.511624  , -1.4201334 ,  1.3836174 ,  0.76095176,\n",
       "        1.7128066 ,  1.6338425 ,  0.97855914, -0.58630663,  0.04052142,\n",
       "        1.4990216 , -0.6120709 ,  0.34216446,  1.2269781 , -0.7331079 ,\n",
       "        0.28988826, -1.6149817 ,  0.06579812, -0.38333467,  2.6606805 ,\n",
       "       -0.73257726,  0.76792926,  0.7120777 , -1.070558  ,  0.3648169 ,\n",
       "       -0.0974213 , -0.57836366, -0.7039345 , -0.8626117 , -1.1392889 ,\n",
       "        0.10586864, -1.0720205 ,  0.40054244, -0.2018465 , -0.61307126,\n",
       "       -0.33859354, -1.122713  , -1.6544468 ,  0.60441816,  0.19429725,\n",
       "       -1.1165631 , -0.9799833 , -0.09096891,  0.738707  , -0.04409248,\n",
       "       -0.90553343,  0.09035312,  0.48441607,  0.02737492, -2.0435777 ,\n",
       "       -1.0324227 ,  0.27375147,  0.67979807, -1.0748622 , -0.42728865,\n",
       "        0.16279283,  0.8520845 , -0.9565703 , -0.87144285, -0.896859  ,\n",
       "       -0.13681157, -1.6245799 , -0.94673586, -0.10711344,  0.26482955,\n",
       "       -0.7096814 ,  0.51472443,  0.07931201, -0.64451176,  0.23317836,\n",
       "       -0.99456304, -0.6037282 , -0.30126825, -0.2407722 , -0.5815554 ,\n",
       "        0.90908545, -0.13503142,  0.92870754,  0.53762966, -0.4051767 ,\n",
       "        0.57714945, -1.5390381 , -0.5968234 , -0.4328885 ,  0.27584016,\n",
       "        1.2907878 , -0.27741367,  0.79397225,  0.81735855,  0.28398368,\n",
       "        0.16452058,  0.5446047 ,  0.33337557, -0.3194104 ,  0.42003158,\n",
       "       -1.0428597 , -1.0027517 ,  0.88293934,  0.00698465,  0.85776836,\n",
       "        0.10181633, -0.18918826,  0.80348486,  1.3629737 ,  0.64027655,\n",
       "       -1.4175967 , -0.18291256, -0.77803403,  0.7426824 ,  1.3948292 ,\n",
       "       -0.40693477, -0.0824461 ,  0.19771498, -0.3384907 , -0.3920192 ,\n",
       "        0.11154885, -1.0337677 , -0.5010414 ,  0.5736661 ,  0.54885614,\n",
       "       -0.8232497 ,  0.7340983 , -1.3724605 ,  0.12596679,  0.57345545,\n",
       "       -1.9487482 ,  0.11939111, -0.14644669, -1.5118759 , -0.54452664,\n",
       "       -1.4689231 ,  0.4425745 ,  0.82843256, -0.21403207, -0.38820177,\n",
       "        0.09582804, -0.54077566,  1.1043701 , -1.3360485 ,  0.33266404,\n",
       "       -0.44335234,  1.5374061 , -0.2597146 ,  0.30914196, -0.48028997],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/Exploration/Exploration_06/ko.bin'\n",
    "word2vec = Word2Vec.load(word2vec_path) # 메모리가 많이 소모되므로 가장 많이 사용되는 상위 100만개로 limit\n",
    "vector = word2vec['굳']\n",
    "vector     # 300dim의 워드 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc84833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624/464520198.py:2: DeprecationWarning: Call to deprecated `similar_by_word` (Method will be removed in 4.0.0, use self.wv.similar_by_word() instead).\n",
      "  word2vec.similar_by_word(\"사랑\")  # 학습이 잘 되어 유사함\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('슬픔', 0.7216662764549255),\n",
       " ('행복', 0.6759077310562134),\n",
       " ('절망', 0.6468985080718994),\n",
       " ('기쁨', 0.6458414196968079),\n",
       " ('이별', 0.6334798336029053),\n",
       " ('추억', 0.6320937275886536),\n",
       " ('인생', 0.6216273307800293),\n",
       " ('애정', 0.6206069588661194),\n",
       " ('연인', 0.6186063289642334),\n",
       " ('유혹', 0.5965287685394287)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사한 단어와 그 유사도 확인\n",
    "word2vec.similar_by_word(\"사랑\")  # 학습이 잘 되어 유사함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "259f4b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_624/253393674.py:9: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if index_to_word[i] in word2vec:\n",
      "/tmp/ipykernel_624/253393674.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  embedding_matrix[i] = word2vec[index_to_word[i]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab_size = 10000    # 어휘 사전의 크기(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩 차례대로 카피\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa007569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 41, 200)           2000000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 512)               1460224   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 4104      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,464,337\n",
      "Trainable params: 3,464,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기(10,000개의 단어)\n",
    "word_vector_dim = 200  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.LSTM(512))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d2ca85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "196/196 [==============================] - 15s 69ms/step - loss: 0.6325 - accuracy: 0.5916 - val_loss: 0.4608 - val_accuracy: 0.7794\n",
      "Epoch 2/5\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.3730 - accuracy: 0.8348 - val_loss: 0.3350 - val_accuracy: 0.8540\n",
      "Epoch 3/5\n",
      "196/196 [==============================] - 14s 70ms/step - loss: 0.2927 - accuracy: 0.8763 - val_loss: 0.3189 - val_accuracy: 0.8625\n",
      "Epoch 4/5\n",
      "196/196 [==============================] - 14s 71ms/step - loss: 0.2521 - accuracy: 0.8965 - val_loss: 0.3180 - val_accuracy: 0.8666\n",
      "Epoch 5/5\n",
      "196/196 [==============================] - 14s 73ms/step - loss: 0.2113 - accuracy: 0.9151 - val_loss: 0.3307 - val_accuracy: 0.8607\n"
     ]
    }
   ],
   "source": [
    "# 학습 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=5  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(X,\n",
    "                    y,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4533021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1537/1537 - 5s - loss: 0.3352 - accuracy: 0.8581\n",
      "[0.3352018892765045, 0.8581483960151672]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)   # 정확도가 0.85으로 개선됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8cebaf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
